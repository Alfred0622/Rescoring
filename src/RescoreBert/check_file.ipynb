{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/disk6/Alfred/Rescoring/data/aishell2/data/withLM/train/data.json\") as f:\n",
    "    gen_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/disk6/Alfred/Rescoring/data/aishell2/raw/withLM/train/data.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(gen_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =0\n",
    "s = []\n",
    "for d in data['utts'].keys():\n",
    "    if (len(data['utts'][d]['output'])) <= 1:\n",
    "        count += 1\n",
    "        s.append(d)\n",
    "\n",
    "print(f'{count}')\n",
    "for a in s:\n",
    "    print(f\"{a}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =0\n",
    "s = []\n",
    "for d in gen_data:\n",
    "    if (len(d['hyps'])) <= 1:\n",
    "        count += 1\n",
    "        s.append(d)\n",
    "\n",
    "print(f'{count}')\n",
    "for a in s:\n",
    "    print(f\"{a}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_no50 = 0\n",
    "for d in gen_data:\n",
    "    if (len(d['token']) != 50):\n",
    "        num_no50 += 1\n",
    "        print(f\"{d['name']} is {len(d['token'])}\")\n",
    "print(num_no50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_no50 = 0\n",
    "for d in gen_data:\n",
    "    if (len(d['pll']) != len(d['token'])):\n",
    "        print(f\"illegal:{d['name']}\")\n",
    "    if (len(d['pll']) != 50):\n",
    "        num_no50 += 1\n",
    "        print(f\"{d['name']} is {len(d['pll'])}\")\n",
    "print(num_no50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_num = 16\n",
    "print(len(data['utts'].keys()))\n",
    "save_num = len(data['utts'].keys()) // 16\n",
    "print(save_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data['utts'].keys():\n",
    "    print(type(data['utts'][d]['output']))\n",
    "    if (isinstance(data['utts'][d]['output'], dict)):\n",
    "        print(f\"{data['utts'][d]['output'].keys()}\")\n",
    "    print(f\"{len(data['utts'][d]['output'])}\")\n",
    "    print(f\"{data['utts'][d]['output'][0]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 126149/126149 [06:08<00:00, 342.43it/s]\n",
      "100%|██████████████████████████████████████████████████████| 126149/126149 [06:19<00:00, 332.47it/s]\n",
      "100%|██████████████████████████████████████████████████████| 126149/126149 [06:09<00:00, 341.16it/s]\n",
      "100%|██████████████████████████████████████████████████████| 126149/126149 [06:17<00:00, 334.57it/s]\n",
      "100%|██████████████████████████████████████████████████████| 126149/126149 [05:50<00:00, 359.79it/s]\n",
      "100%|██████████████████████████████████████████████████████| 126148/126148 [05:35<00:00, 376.48it/s]\n",
      "100%|██████████████████████████████████████████████████████| 126148/126148 [05:33<00:00, 378.00it/s]\n",
      "100%|██████████████████████████████████████████████████████| 126148/126148 [05:39<00:00, 371.08it/s]\n"
     ]
    }
   ],
   "source": [
    "data_count = 0\n",
    "for i in range(8):\n",
    "    data_list = []\n",
    "    with open(f\"/mnt/disk6/Alfred/Rescoring/data/aishell2/raw/withLM/train/data.{i+1}.json\") as f:\n",
    "        data_json = json.load(f)\n",
    "        for d in tqdm(data_json['utts'].keys(), ncols = 100):\n",
    "            hyps = []\n",
    "            errs = []\n",
    "            scores = []\n",
    "            ref = data_json['utts'][d]['output'][0][\"token\"].replace(\"<eos>\", \"\")\n",
    "            if ('am_score' in data_json['utts'][d]['output'][0].keys()):\n",
    "                am_scores = []\n",
    "            else:\n",
    "                am_scores = None\n",
    "            \n",
    "            if ('ctc_score' in data_json['utts'][d]['output'][0].keys()):\n",
    "                ctc_scores = []\n",
    "            else:\n",
    "                ctc_scores = None\n",
    "\n",
    "            if ('lm_score' in data_json['utts'][d]['output'][0].keys()):\n",
    "                lm_scores = []\n",
    "            else:\n",
    "                lm_scores = None\n",
    "            \n",
    "            for hyp in (data_json['utts'][d]['output']):\n",
    "                hyp_token = hyp['rec_token'].replace(\"<eos>\", \"\")\n",
    "                hyp_token = hyp_token.replace(\" \", \"\")\n",
    "                hyp_token = \" \".join([token for token in hyp_token])\n",
    "\n",
    "                if (am_scores is not None):\n",
    "                    am_scores.append(hyp['am_score'])\n",
    "                if (ctc_scores is not None):\n",
    "                    ctc_scores.append(hyp['ctc_score'])\n",
    "                if (lm_scores is not None):\n",
    "                    lm_scores.append(hyp['lm_score'])\n",
    "\n",
    "                scores.append(hyp['score'])\n",
    "\n",
    "                measures = jiwer.compute_measures(ref, hyp_token)\n",
    "\n",
    "                errs.append(\n",
    "                    {\n",
    "                        'err': measures['wer'],\n",
    "                        'hit': measures['hits'],\n",
    "                        'sub': measures['substitutions'],\n",
    "                        'del': measures['deletions'],\n",
    "                        'ins': measures['insertions'],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                hyps.append(hyp_token)\n",
    "            \n",
    "            data_list.append(\n",
    "                {\n",
    "                    'name': d,\n",
    "                    'hyps': hyps,\n",
    "                    'am_score': am_scores,\n",
    "                    'ctc_score': ctc_scores,\n",
    "                    \"lm_score\": None if lm_scores is None else lm_scores,\n",
    "                    \"score\": scores,\n",
    "                    'err': errs,\n",
    "                    'ref': ref.lower()\n",
    "                }\n",
    "            )\n",
    "            data_count += 1\n",
    "    with open(f\"/mnt/disk6/Alfred/Rescoring/data/aishell2/data/withLM/train/data_{i+1}.json\", 'w') as f:\n",
    "        json.dump(data_list, f, ensure_ascii=False, indent = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009189\n"
     ]
    }
   ],
   "source": [
    "data_len = 0\n",
    "for i in range(8):\n",
    "    \n",
    "    with open(f\"/mnt/disk6/Alfred/Rescoring/data/aishell2/data/withLM/train/data_{i+1}.json\") as f:\n",
    "        data_json = json.load(f)\n",
    "        data_len += len(data_json)\n",
    "        # print(len(data_json))\n",
    "\n",
    "print(data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count = 0\n",
    "file_count = 1\n",
    "\n",
    "data_list = []\n",
    "for d in tqdm(data['utts'].keys(), ncols = 100):\n",
    "    hyps = []\n",
    "    errs = []\n",
    "    scores = []\n",
    "    ref = data['utts'][d]['output'][0][\"token\"].replace(\"<eos>\", \"\")\n",
    "    if ('am_score' in data['utts'][d]['output'][0].keys()):\n",
    "        am_scores = []\n",
    "    else:\n",
    "        am_scores = None\n",
    "    \n",
    "    if ('ctc_score' in data['utts'][d]['output'][0].keys()):\n",
    "        ctc_scores = []\n",
    "    else:\n",
    "        ctc_scores = None\n",
    "\n",
    "    if ('lm_score' in data['utts'][d]['output'][0].keys()):\n",
    "        lm_scores = []\n",
    "    else:\n",
    "        lm_scores = None\n",
    "    \n",
    "    for hyp in (data['utts'][d]['output']):\n",
    "        hyp_token = hyp['rec_token'].replace(\"<eos>\", \"\")\n",
    "        hyp_token = hyp_token.replace(\" \", \"\")\n",
    "        hyp_token = \" \".join([token for token in hyp_token])\n",
    "\n",
    "        if (am_scores is not None):\n",
    "            am_scores.append(hyp['am_score'])\n",
    "        if (ctc_scores is not None):\n",
    "            ctc_scores.append(hyp['ctc_score'])\n",
    "        if (lm_scores is not None):\n",
    "            lm_scores.append(hyp['lm_score'])\n",
    "\n",
    "        scores.append(hyp['score'])\n",
    "\n",
    "        measures = jiwer.compute_measures(ref, hyp_token)\n",
    "\n",
    "        errs.append(\n",
    "            {\n",
    "                'err': measures['wer'],\n",
    "                'hit': measures['hits'],\n",
    "                'sub': measures['substitutions'],\n",
    "                'del': measures['deletions'],\n",
    "                'ins': measures['insertions'],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        hyps.append(hyp_token)\n",
    "    \n",
    "    data_list.append(\n",
    "        {\n",
    "            'name': d,\n",
    "            'hyps': hyps,\n",
    "            'am_score': am_scores,\n",
    "            'ctc_score': ctc_scores,\n",
    "            \"lm_score\": None if lm_scores is None else lm_scores,\n",
    "            \"score\": scores,\n",
    "            'err': errs,\n",
    "            'ref': ref.lower()\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    data_count += 1\n",
    "\n",
    "    if (data_count % save_num == 0 and data_count > 0 and file_count < 16):\n",
    "        with open(f'/mnt/disk6/Alfred/Rescoring/data/aishell2/raw/withLM/train/data_{file_count}.json', 'w') as f:\n",
    "            json.dump(data_list, f, ensure_ascii = False, indent = 1)\n",
    "        data_list = []\n",
    "        data_count = 0\n",
    "        print(f'file saved:/mnt/disk6/Alfred/Rescoring/data/aishell2/raw/withLM/train/data_{file_count}.json')\n",
    "        file_count += 1\n",
    "\n",
    "with open(f'/mnt/disk6/Alfred/Rescoring/data/aishell2/raw/withLM/train/data_{file_count}.json', 'w') as f:\n",
    "    print(f'file saved:/mnt/disk6/Alfred/Rescoring/data/aishell2/raw/withLM/train/data_{file_count}.json')\n",
    "    json.dump(data_list, f, ensure_ascii = False, indent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data = []\n",
    "for i in range(1, 17):\n",
    "    print(f'i:{i}')\n",
    "    with open(f'/mnt/disk6/Alfred/Rescoring/data/aishell2/raw/withLM/train/data_{i}.json') as f:\n",
    "        data_json = json.load(f)\n",
    "        combine_data += data_json\n",
    "\n",
    "with open(f'/mnt/disk6/Alfred/Rescoring/data/aishell2/data/withLM/train/data.json', 'w') as f:\n",
    "     json.dump(combine_data, f, ensure_ascii = False, indent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:1\n",
      "i:2\n",
      "i:3\n",
      "i:4\n",
      "i:5\n",
      "i:6\n",
      "i:7\n",
      "i:8\n"
     ]
    }
   ],
   "source": [
    "data_list = list()\n",
    "for i in range(1, 9):\n",
    "    print(f'i:{i}')\n",
    "    with open(f'/mnt/disk6/Alfred/Rescoring/data/aishell2/data/withLM/train/data_{i}.json') as f:\n",
    "        data_json = json.load(f)\n",
    "        data_list += data_json\n",
    "\n",
    "with open(f'/mnt/disk6/Alfred/Rescoring/data/aishell2/data/withLM/train/data.json', 'w') as f:\n",
    "    json.dump(data_list, f, ensure_ascii= False, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_count:1009189\n"
     ]
    }
   ],
   "source": [
    "data_count = 0\n",
    "with open(f'/mnt/disk6/Alfred/Rescoring/data/aishell2/data/withLM/train/data.json') as f:\n",
    "    data_json = json.load(f)\n",
    "    for data in data_json:\n",
    "        if (len(data['hyps']) == 1):\n",
    "            print(data['name'])\n",
    "        data_count += 1\n",
    "\n",
    "print(f'data_count:{data_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
