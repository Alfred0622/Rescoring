{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from nBestAligner.nBestAlign import align\n",
            "import torch"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "nbest = [\n",
            "    [1,2,3,4,6],\n",
            "    [0, 1, 2, 10],\n",
            "    [2,3,5,7],\n",
            "    [5,10, 4, 8],\n",
            "]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "device = 'cuda' if  torch.cuda.is_available() else 'cpu'"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "device = torch.device(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "align(nbest, 4)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sentence_transformers import SentenceTransformer"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "model = SentenceTransformer(\n",
            "                \"cyclone/simcse-chinese-roberta-wwm-ext\",\n",
            "                device = device\n",
            "            )\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "tokens = ['广州市房地产中介协会分析'].to(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "embedding = model.encode(tokens)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "embedding.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from transformers import BertTokenizer\n",
            "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "token = tokenizer.convert_tokens_to_ids(list('广州市房地产中介协会分析'))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "model.encode(token)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "import logging\n",
            "from torch.nn.functional import log_softmax\n",
            "from transformers import (\n",
            "    BertForMaskedLM,\n",
            "    AutoModelForCausalLM,\n",
            "    BertTokenizerFast,\n",
            ")\n",
            "from torch.optim import AdamW"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "model = AutoModelForCausalLM.from_pretrained('ckiplab/gpt2-base-chinese')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "seq = torch.tensor([\n",
            "    [\n",
            "                101,\n",
            "                2408,\n",
            "                2336,\n",
            "                2356,\n",
            "                2791,\n",
            "                1765,\n",
            "                772,\n",
            "                704,\n",
            "                792,\n",
            "                1291,\n",
            "                833,\n",
            "                1146,\n",
            "                3358,\n",
            "                102\n",
            "            ],\n",
            "            [\n",
            "                101,\n",
            "                2408,\n",
            "                2336,\n",
            "                2356,\n",
            "                2791,\n",
            "                1765,\n",
            "                772,\n",
            "                704,\n",
            "                6381,\n",
            "                1291,\n",
            "                833,\n",
            "                102,\n",
            "                0,\n",
            "                0\n",
            "            ]\n",
            "        ])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output = model(seq)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output.logits.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "non_cls_index = (seq != 101)\n",
            "non_sep_index = (seq != 102)\n",
            "non_pad_index = (seq != 0)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "temp_logit = torch.logical_and(non_cls_index, non_sep_index)\n",
            "token_index = torch.logical_and(temp_logit, non_pad_index)\n",
            "token_index.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "real_token = seq[token_index]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "seq[token_index]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "logit = output.logits"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "logit.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "seq.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "score = logit.gather(2, seq.unsqueeze(2)).squeeze(-1)\n",
            "score.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "true_index = torch.nonzero(token_index)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "sum_score = 0\n",
            "last_i = -1\n",
            "result = []\n",
            "for i, j in true_index:\n",
            "    if (last_i >= 0 and last_i != i):\n",
            "        print('flush')\n",
            "        result.append(sum_score)\n",
            "        sum_score = 0\n",
            "    print(i)\n",
            "    sum_score += score[i][j].item()\n",
            "    last_i = i.item()\n",
            "result.append(sum_score)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "result"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "exp_logit = torch.exp(logit)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "torch.sum(logit, -1)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "string = \"你好啊\"\n",
            "list(string)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from transformers import BertTokenizer"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "tokenizer = BertTokenizer.from_pretrained('fnlp/bart-base-chinese')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "string1 = '我要吃飯要吃飯吃飯飯'\n",
            "string2 = '我要吃飯#要吃飯#吃飯#飯'"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "str_list1 = [x for x in string1]\n",
            "str_list2 = [x for x in string2]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "tokenizer.convert_ids_to_tokens([0])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "print(str_list1)\n",
            "print(str_list2)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "print(tokenizer.tokenize(string1))\n",
            "print(tokenizer.tokenize(string2))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "str_list2 == tokenizer.tokenize(string2)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "tokenizer.convert_tokens_to_ids(str_list2)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "string = \"00010002\"\n",
            "string = string.lstrip('0')\n",
            "print(string)\n",
            "split_string = [string[max(i - 4, 0) : i] for i in range(len(string), 0 , -4)]\n",
            "split_string[::-1]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "data = [i for i in range(1,11)]\n",
            "label = [i for i in range(-1, -11, -1)]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from torch.utils.data import Dataset, DataLoader"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "class testData(Dataset):\n",
            "    def __init__(self, data, label):\n",
            "        self.input = data\n",
            "        self.label = label\n",
            "    def __getitem__(self, idx):\n",
            "        return (\n",
            "            self.input[idx], self.label[idx]\n",
            "        )\n",
            "    def __len__(self):\n",
            "        return len(self.input)\n",
            "\n",
            "def collate(sample):\n",
            "    for s in sample:\n",
            "        a = [unit for unit in s[0]]\n",
            "        b = [unit for unit in s[1]]\n",
            "    return a, b"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "test = testData(data, label)\n",
            "loader = DataLoader(\n",
            "    dataset = testData,\n",
            "    batch_size = 1,\n",
            "    collate_fn = collate,\n",
            "    shuffle = True\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "espnet",
         "language": "python",
         "name": "espnet"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.8.0"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
