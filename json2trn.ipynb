{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import json"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [],
         "source": [
            "data_name = 'tedlium2'\n",
            "recog_set = ['train','dev', 'test']\n",
            "setting = ['noLM','withLM']\n",
            "nbest = 50"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "noLM:train\n",
                  "correct:92788\n",
                  "wrong:3\n",
                  "noLM:dev\n",
                  "correct:507\n",
                  "wrong:0\n",
                  "noLM:test\n",
                  "correct:1155\n",
                  "wrong:0\n",
                  "withLM:train\n",
                  "correct:92731\n",
                  "wrong:60\n",
                  "withLM:dev\n",
                  "correct:1152\n",
                  "wrong:3\n",
                  "withLM:test\n",
                  "correct:506\n",
                  "wrong:1\n"
               ]
            }
         ],
         "source": [
            "for s in setting:\n",
            "    for r in recog_set:\n",
            "        print(f'{s}:{r}')\n",
            "        json_name = f'./data/{data_name}/raw/{s}/{r}/data.json'\n",
            "        with open(json_name, 'r') as f,\\\n",
            "            open(f'./data/{data_name}/raw/{s}/{r}/hyp.trn', 'w') as hyp,\\\n",
            "            open(f'./data/{data_name}/raw/{s}/{r}/ref.trn', 'w') as ref:\n",
            "            j = json.load(f)\n",
            "            correct = 0\n",
            "            wrong = 0\n",
            "            for k in j['utts'].keys():\n",
            "                count = 0\n",
            "                # assert(len(j['utts'][k]['output']) == nbest)\n",
            "                for i, h in enumerate(j['utts'][k]['output']):\n",
            "                    count += 1\n",
            "                    # print(j['utts'][k]['output'])\n",
            "                    seq = [t for t in h['rec_token'].split()]\n",
            "                    hyp_seq = \" \".join(seq[:-1])\n",
            "                    hyp.write( f'{hyp_seq} ({j[\"utts\"][k][\"utt2spk\"].replace(\"-\", \"_\")}-{k}-hyp[{i}])\\n' )\n",
            "                    # hyp.write(hyp_seq + '(' + j[\"utts\"][k][\"utt2spk\"].replace(\"-\", \"_\") + '-' + 'hyp' + i + ')')\n",
            "\n",
            "                    ref_seq = h[\"token\"]\n",
            "                    ref.write( f'{ref_seq} ({j[\"utts\"][k][\"utt2spk\"].replace(\"-\", \"_\")}-{k}-hyp[{i}])\\n' )\n",
            "                if (count == nbest):\n",
            "                    correct += 1\n",
            "                else:\n",
            "                    wrong += 1\n",
            "            print(f'correct:{correct}')\n",
            "            print(f'wrong:{wrong}')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "上面code跑完 執行espnet的\n",
            "```sclite -r ./ref.trn -h  ./hyp.trn -i rm -o all stdout >  ./result.txt```"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "\n",
            "\n",
            "如果是tedlium2 or librispeech:\n",
            "```\n",
            " /mnt/disk3/Alfred/espnet/utils/spm_decode --model ../../../lang_char/train_trim_unigram500.model --input_format=piece < ./ref.trn | sed -e \"s/▁/ /g\" > ./ref.wrd.trn\n",
            " /mnt/disk3/Alfred/espnet/utils/spm_decode --model ../../../lang_char/train_trim_unigram500.model --input_format=piece < ./hyp.trn | sed -e \"s/▁/ /g\" > ./hyp.wrd.trn\n",
            "sclite -r ./ref.wrd.trn trn -h ./hyp.wrd.trn trn -i rm -o all stdout > ./result.wrd.txt\n",
            "```"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 40,
         "metadata": {},
         "outputs": [],
         "source": [
            "data_name = 'tedlium2'\n",
            "setting = ['noLM','withLM']\n",
            "recog_set = ['dev', 'test']\n",
            "nbest = 50\n",
            "check_dataset = True"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 42,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".wrd.txt\n",
                  "noLM:dev\n",
                  "len of best_num:507\n",
                  "len of err:507\n",
                  "len:507\n",
                  "len(nbest_token):507\n",
                  "len(ref_text):507\n",
                  "len(nbest_score):507\n",
                  "len(nbest_am_score):507\n",
                  "len(nbest_ctc_score):507\n",
                  "len of dataset:507\n",
                  "noLM:test\n",
                  "len of best_num:1155\n",
                  "len of err:1155\n",
                  "len:1155\n",
                  "len(nbest_token):1155\n",
                  "len(ref_text):1155\n",
                  "len(nbest_score):1155\n",
                  "len(nbest_am_score):1155\n",
                  "len(nbest_ctc_score):1155\n",
                  "len of dataset:1155\n",
                  "withLM:dev\n",
                  "len of best_num:507\n",
                  "len of err:507\n",
                  "len:507\n",
                  "len(nbest_token):507\n",
                  "len(ref_text):507\n",
                  "len(nbest_score):507\n",
                  "len(nbest_am_score):507\n",
                  "len(nbest_ctc_score):507\n",
                  "len of dataset:507\n",
                  "withLM:test\n",
                  "len of best_num:1155\n",
                  "len of err:1155\n",
                  "len:1155\n",
                  "len(nbest_token):1155\n",
                  "len(ref_text):1155\n",
                  "len(nbest_score):1155\n",
                  "len(nbest_am_score):1155\n",
                  "len(nbest_ctc_score):1155\n",
                  "len of dataset:1155\n"
               ]
            }
         ],
         "source": [
            "file_type = '.txt'\n",
            "trn_name = '.trn'\n",
            "if (data_name in ['tedlium2', 'librispeech'] and check_dataset):\n",
            "    file_type = \".wrd.txt\"\n",
            "    trn_name = '.wrd.trn'\n",
            "\n",
            "print(file_type)\n",
            "for s in setting:\n",
            "    for task in recog_set:\n",
            "        nbest_err = []\n",
            "        nbest_num = []\n",
            "        print(f'{s}:{task}')\n",
            "        with open(f'./data/{data_name}/raw/{s}/{task}/data.json', 'r') as f:\n",
            "            json_data = json.load(f)\n",
            "            for k in json_data['utts'].keys():\n",
            "                nbest_num.append(len(json_data['utts'][k]['output']))\n",
            "            print(f'len of best_num:{len(nbest_num)}')\n",
            "        \n",
            "        with open(f'./data/{data_name}/raw/{s}/{task}/result{file_type}', 'r') as f, \\\n",
            "             open(f'./data/{data_name}/raw/{s}/{task}/ref{trn_name}', 'r') as rf,\\\n",
            "             open(f'./data/{data_name}/raw/{s}/{task}/hyp{trn_name}', 'r') as hf :\n",
            "            temp_err = []\n",
            "            nbest_index = 0\n",
            "            for i, line in enumerate(f):\n",
            "                if ('Scores:' in line):\n",
            "                    scores = line.split()[-4:]\n",
            "                    scores = [int(s) for s in scores]\n",
            "                    temp_err.append(scores)\n",
            "                    if (len(temp_err) == nbest_num[nbest_index]):\n",
            "                        nbest_err.append(temp_err)\n",
            "                        temp_err = []\n",
            "                        nbest_index += 1\n",
            "\n",
            "            nbest_token = []\n",
            "            temp_token = []\n",
            "            nbest_index = 0\n",
            "            for i, line in enumerate(hf):\n",
            "                parenthesis_index = line.find('(')\n",
            "                token = line[ : parenthesis_index]\n",
            "                temp_token.append(token.strip())\n",
            "\n",
            "                if (len(temp_token) == nbest_num[nbest_index]):\n",
            "                    nbest_token.append(temp_token)\n",
            "                    temp_token = []\n",
            "                    nbest_index += 1\n",
            "\n",
            "            ref_text = []\n",
            "            nbest_index = 0\n",
            "            line_count = 0\n",
            "            for i, line in enumerate(rf):\n",
            "                line_count += 1\n",
            "                if (line_count == nbest_num[nbest_index]):\n",
            "                    parenthesis_index = line.find('(')\n",
            "                    token = line[ : parenthesis_index]\n",
            "                    ref_text.append(token.strip())\n",
            "                    nbest_index += 1\n",
            "                    line_count = 0\n",
            "\n",
            "            print(f'len of err:{len(nbest_err)}')\n",
            "\n",
            "            names = []\n",
            "            nbest_am_score = []\n",
            "            nbest_ctc_score = []\n",
            "            nbest_score = []\n",
            "\n",
            "            if (s == 'withLM'):\n",
            "                nbest_lm_score = []\n",
            "\n",
            "            print(f\"len:{len(json_data['utts'].keys())}\")\n",
            "            for k in json_data['utts'].keys():\n",
            "                am_score = []\n",
            "                ctc_score = []\n",
            "                score = []\n",
            "\n",
            "                if (s == 'withLM'):\n",
            "                    lm_score = []\n",
            "                    \n",
            "                for i, h in enumerate(json_data['utts'][k]['output']):\n",
            "                    score.append(h['score'])\n",
            "                    am_score.append(h['am_score'])\n",
            "                    ctc_score.append(h['ctc_score'])\n",
            "\n",
            "                    if (s == 'withLM'):\n",
            "                        lm_score.append(h['lm_score'])\n",
            "\n",
            "                nbest_score.append(score)\n",
            "                nbest_am_score.append(am_score)\n",
            "                nbest_ctc_score.append(ctc_score)\n",
            "\n",
            "                if (s == 'withLM'):\n",
            "                    nbest_lm_score.append(lm_score)\n",
            "\n",
            "                names.append(k)\n",
            "            dataset = []\n",
            "            if (s != 'withLM'):\n",
            "                for name, token, score, am_score, ctc_score, err, ref in zip(\n",
            "                    names, \n",
            "                    nbest_token, \n",
            "                    nbest_score,\n",
            "                    nbest_am_score,\n",
            "                    nbest_ctc_score, \n",
            "                    nbest_err, \n",
            "                    ref_text\n",
            "                ):\n",
            "                    dataset.append(\n",
            "                        {\n",
            "                            'name': name,\n",
            "                            'hyp': token,\n",
            "                            'am_score': am_score,\n",
            "                            'ctc_score': ctc_score,\n",
            "                            'score': score,\n",
            "                            'err': err,\n",
            "                            'ref': ref,\n",
            "                        }\n",
            "                    )\n",
            "\n",
            "            else:\n",
            "                for name, token, score, am_score, ctc_score, lm_score ,err, ref in zip(\n",
            "                    names, \n",
            "                    nbest_token, \n",
            "                    nbest_score,\n",
            "                    nbest_am_score,\n",
            "                    nbest_ctc_score,\n",
            "                    nbest_lm_score,\n",
            "                    nbest_err, \n",
            "                    ref_text\n",
            "                ):\n",
            "                    dataset.append(\n",
            "                        {\n",
            "                            'name': name,\n",
            "                            'hyp': token,\n",
            "                            'am_score': am_score,\n",
            "                            'ctc_score': ctc_score,\n",
            "                            'lm_score': lm_score,\n",
            "                            'score': score,\n",
            "                            'err': err,\n",
            "                            'ref': ref,\n",
            "                        }\n",
            "                    )\n",
            "            print(f\"len of dataset:{len(dataset)}\")\n",
            "\n",
            "        with open(f\"./data/{data_name}/data/{s}/{task}/data.json\", 'w') as f:\n",
            "            json.dump(dataset, f, ensure_ascii=False, indent = 4)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Result trn"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "dataname = 'aishell'\n",
            "name = \"Audio_Aware\"\n",
            "setting = 'noLM'\n",
            "recog_set = ['dev', 'test']\n",
            "nbest = 3\n",
            "best_type = 'align_concat'\n",
            "training = 'MD'"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# BART"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "for r in recog_set:\n",
            "    json_name = f\"./src/Correction/data/{dataname}/{setting}/{r}/{nbest}{best_type}/correct_data.json\"\n",
            "    with open(json_name, 'r') as f, \\\n",
            "            open(f'./src/Correction/data/{dataname}/{setting}/{r}/{nbest}{best_type}/hyp.trn', 'w') as hyp, \\\n",
            "            open(f'./src/Correction/data/{dataname}/{setting}/{r}/{nbest}{best_type}/ref.trn', 'w') as ref:\n",
            "        j = json.load(f)\n",
            "        for k in j['utts'].keys():\n",
            "                # print(j['utts'][k]['output'])\n",
            "            hyp_seq = j['utts'][k]['hyp']\n",
            "            hyp.write( f'{hyp_seq} ({k})\\n' )\n",
            "            # hyp.write(hyp_seq + '(' + j[\"utts\"][k][\"utt2spk\"].replace(\"-\", \"_\") + '-' + 'hyp' + i + ')')\n",
            "            ref_seq = j['utts'][k]['ref']\n",
            "            ref.write( f'{ref_seq} ({k})\\n' )"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# RescoreBert"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "sclite -r ./50best_hyp.trn -h  ./50best_ref.trn -i rm -o all stdout >  ./50best_result.txt\n",
                  "sclite -r ./50best_hyp.trn -h  ./50best_ref.trn -i rm -o all stdout >  ./50best_result.txt\n"
               ]
            }
         ],
         "source": [
            "for task in recog_set:\n",
            "    json_name = f\"./data/{dataname}/{task}/{training}/{setting}/{nbest}best_rescore_data.json\"\n",
            "    with open(json_name, 'r') as f, \\\n",
            "        open(f'./data/{dataname}/{task}/{training}/{setting}/{nbest}best_hyp.trn', 'w') as hyp, \\\n",
            "        open(f'./data/{dataname}/{task}/{training}/{setting}/{nbest}best_ref.trn', 'w') as ref:\n",
            "        j = json.load(f)\n",
            "        for k in j['utts'].keys():\n",
            "                # print(j['utts'][k]['output'])\n",
            "            hyp_seq = j['utts'][k]['output']['rec_token']\n",
            "            hyp.write( f'{hyp_seq} ({k})\\n' )\n",
            "            # hyp.write(hyp_seq + '(' + j[\"utts\"][k][\"utt2spk\"].replace(\"-\", \"_\") + '-' + 'hyp' + i + ')')\n",
            "            ref_seq = j['utts'][k]['output']['text_token']\n",
            "            ref.write( f'{ref_seq} ({k})\\n' )\n",
            "    print(f'sclite -r ./{nbest}best_hyp.trn -h  ./{nbest}best_ref.trn -i rm -o all stdout >  ./{nbest}best_result.txt')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "for r in recog_set:\n",
            "    json_name = f'./data/{dataset}_{r}/{name}/rescore_data.json'\n",
            "    with open(json_name, 'r') as f, open(f'./data/{dataset}_{r}/{name}/hyp_rescore.trn', 'w') as hyp, open(f'./data/{dataset}_{r}/{name}/ref_rescore.trn', 'w') as ref:\n",
            "        j = json.load(f)\n",
            "        for k in j['utts'].keys():\n",
            "                # print(j['utts'][k]['output'])\n",
            "            hyp_seq = j['utts'][k]['rec_text']\n",
            "            hyp.write( f'{hyp_seq} ({k})\\n' )\n",
            "            # hyp.write(hyp_seq + '(' + j[\"utts\"][k][\"utt2spk\"].replace(\"-\", \"_\") + '-' + 'hyp' + i + ')')\n",
            "            ref_seq = j['utts'][k]['ref_text']\n",
            "            ref.write( f'{ref_seq} ({k})\\n' )"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from transformers import BertTokenizer\n",
            "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import json\n",
            "import torch\n",
            "# for r in recog_set:\n",
            "best_weight = 0\n",
            "best_cer = 100\n",
            "with open(f\"./data/{dataname}/dev/{nbest}best_{training}_rescore_data_{setting}.json\") as f:\n",
            "    data = json.load(f)\n",
            "    \n",
            "    for n in range(101):\n",
            "        weight = n * 0.01\n",
            "        c = 0\n",
            "        s = 0\n",
            "        de = 0\n",
            "        i = 0\n",
            "        for d in data:\n",
            "            score = torch.tensor(d['score'])\n",
            "            pll = torch.tensor(d['pll'])\n",
            "            cer = d['err']\n",
            "                \n",
            "            result = score + weight * pll\n",
            "\n",
            "            max_index = torch.argmax(result).item()\n",
            "\n",
            "            c += cer[max_index][0]\n",
            "            s += cer[max_index][1]\n",
            "            de += cer[max_index][2]\n",
            "            i += cer[max_index][3]\n",
            " \n",
            "        cer = (s + de + i) / (c + s + de)\n",
            "\n",
            "        if (cer < best_cer):\n",
            "            best_cer = cer\n",
            "            best_weight = weight\n",
            "\n",
            "print(f'best weight:{best_weight} with cer:{best_cer}')\n",
            "\n",
            "for task in recog_set:\n",
            "    with open(f\"./data/{dataname}/{task}/{nbest}best_{training}_rescore_data_{setting}.json\", 'r') as f, \\\n",
            "         open(f'./data/{dataname}/{task}/hyp_mlm.trn', 'w') as h,\\\n",
            "         open(f'./data/{dataname}/{task}/ref_mlm.trn', 'w') as g:\n",
            "        data = json.load(f)\n",
            "        for n, d in enumerate(data):\n",
            "            score = torch.tensor(d['score'])\n",
            "            pll = torch.tensor(d['pll'])\n",
            "            cer = d['err']\n",
            "            ref = d['ref'][5:-5]\n",
            "            token = d['token']\n",
            "                \n",
            "            result = score + weight * pll\n",
            "\n",
            "            max_index = torch.argmax(result).item()\n",
            "\n",
            "            best_hyp = token[max_index]\n",
            "            sep = best_hyp.index(102)\n",
            "            hyp_seq = tokenizer.convert_ids_to_tokens(best_hyp[1:sep])\n",
            "\n",
            "            h.write( f'{\" \".join(hyp_seq)} ({r}_{n})\\n' )\n",
            "            g.write( f'{\" \".join(list(ref))} ({r}_{n})\\n')\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3.9.5",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.5"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "a7ccf5fb952618089b6fc9511fb1d1e0b820b57f976eb5c331d871bc3f52c234"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
